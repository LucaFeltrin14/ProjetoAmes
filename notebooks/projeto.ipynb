{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto: Previsão de Preços de Imóveis em Ames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das Bibliotecas Necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas essenciais\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Importação das bibliotecas de pré-processamento e modelagem\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Importação dos modelos de regressão\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Importação das métricas de avaliação\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Importação para visualização dos resultados\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento dos Dados Processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição do caminho para o arquivo processado\n",
    "DATA_DIR = Path.cwd().parent / 'data'\n",
    "processed_file_path = DATA_DIR / 'processed' / 'ames_clean.pkl'\n",
    "\n",
    "# Carregamento dos dados processados\n",
    "with open(processed_file_path, 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão dos Dados em Conjuntos de Treinamento e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição da variável alvo\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Definição das variáveis preditoras\n",
    "X = data.drop('SalePrice', axis=1)\n",
    "\n",
    "# Divisão dos dados em treinamento e teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificação das Colunas Categóricas e Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificação das colunas categóricas e numéricas\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"Colunas Categóricas: {categorical_cols}\")\n",
    "print(f\"Colunas Numéricas: {numerical_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversão das Colunas Categóricas para Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter todas as colunas categóricas para string para evitar erros no encoder\n",
    "X_train[categorical_cols] = X_train[categorical_cols].astype(str)\n",
    "X_test[categorical_cols] = X_test[categorical_cols].astype(str)\n",
    "\n",
    "# Verificação para garantir que a conversão foi bem-sucedida\n",
    "print(X_train[categorical_cols].dtypes)\n",
    "print(X_test[categorical_cols].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_error(y_true, y_pred):\n",
    "    \"\"\"Calcula o Erro Percentual Absoluto Médio (PEA).\n",
    "\n",
    "    Args:\n",
    "        y_true (array-like): Valores reais.\n",
    "        y_pred (array-like): Valores previstos.\n",
    "\n",
    "    Returns:\n",
    "        float: PEA em porcentagem.\n",
    "    \"\"\"\n",
    "    y_true, y_pred = pd.Series(y_true), pd.Series(y_pred)\n",
    "    # Evitar divisão por zero substituindo zeros por um pequeno valor\n",
    "    y_true = y_true.replace(0, 1e-10)\n",
    "    return (abs((y_true - y_pred) / y_true).mean()) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição das Pipelines de Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline para variáveis numéricas\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline para variáveis categóricas\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combinação das pipelines usando ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_pipeline, numerical_cols),\n",
    "    ('cat', categorical_pipeline, categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição dos modelos a serem comparados com seus hiperparâmetros\n",
    "models = {\n",
    "    'Linear Regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'Ridge Regression': {\n",
    "        'model': Ridge(),\n",
    "        'params': {\n",
    "            'regressor__alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "        }\n",
    "    },\n",
    "    'Lasso Regression': {\n",
    "        'model': Lasso(),\n",
    "        'params': {\n",
    "            'regressor__alpha': [0.01, 0.1, 1.0, 10.0]\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {\n",
    "            'regressor__n_estimators': [100, 200],\n",
    "            'regressor__max_depth': [None, 10, 20],\n",
    "            'regressor__min_samples_split': [2, 5],\n",
    "            'regressor__min_samples_leaf': [1, 2]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação das Pipelines de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação das pipelines e configuração do GridSearchCV\n",
    "pipelines = {}\n",
    "for name, config in models.items():\n",
    "    # Pipeline para cada modelo\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', config['model'])\n",
    "    ])\n",
    "    \n",
    "    # GridSearchCV para otimização de hiperparâmetros\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=config['params'],\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    pipelines[name] = grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento de cada modelo com GridSearchCV\n",
    "for name, grid_search in pipelines.items():\n",
    "    try:\n",
    "        print(f\"Iniciando treinamento do modelo: {name}\")\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        print(f\"{name} treinado com sucesso.\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao treinar {name}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação e Comparação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação dos modelos no conjunto de teste\n",
    "results = []\n",
    "\n",
    "for name, grid_search in pipelines.items():\n",
    "    try:\n",
    "        # Previsões\n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        \n",
    "        # Cálculo das métricas\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        percent_error = percentage_error(y_test, y_pred)  # Erro percentual em porcentagem\n",
    "        \n",
    "        # Coleta dos melhores hiperparâmetros\n",
    "        best_params = grid_search.best_params_\n",
    "        \n",
    "        # Armazenamento dos resultados\n",
    "        results.append({\n",
    "            'Modelo': name,\n",
    "            'RMSE': f\"{rmse:.2f}\",\n",
    "            'Erro Percentual (%)': f\"{percent_error:.2f}%\",\n",
    "            'Melhores Hiperparâmetros': best_params\n",
    "        })\n",
    "        \n",
    "        print(f\"{name} avaliado com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao avaliar {name}: {e}\")\n",
    "\n",
    "# Conversão da lista de resultados para DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Exibição dos resultados ordenados por Erro Percentual\n",
    "print(\"\\nResultados dos Modelos:\")\n",
    "print(results_df[['Modelo', 'RMSE', 'Erro Percentual (%)', 'Melhores Hiperparâmetros']].sort_values(by='Erro Percentual (%)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do estilo dos gráficos\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Gráfico de barras para RMSE\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='RMSE', y='Modelo', data=results_df.sort_values('RMSE', ascending=True), palette='viridis')\n",
    "plt.title('Desempenho dos Modelos - RMSE')\n",
    "plt.xlabel('RMSE')\n",
    "plt.ylabel('Modelo')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de barras para Erro Percentual\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='Erro Percentual (%)', y='Modelo', data=results_df.sort_values('Erro Percentual (%)', ascending=True), palette='magma')\n",
    "plt.title('Desempenho dos Modelos - Erro Percentual (%)')\n",
    "plt.xlabel('Erro Percentual (%)')\n",
    "plt.ylabel('Modelo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificação das 10 Features Mais Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialização de um dicionário para armazenar as importâncias das features\n",
    "feature_importances = pd.Series(dtype=float)\n",
    "\n",
    "for name, grid_search in pipelines.items():\n",
    "    try:\n",
    "        model = grid_search.best_estimator_.named_steps['regressor']\n",
    "        \n",
    "        # Obter nomes das features após OneHotEncoder\n",
    "        if hasattr(grid_search.best_estimator_.named_steps['preprocessor'], 'transformers_'):\n",
    "            ohe = grid_search.best_estimator_.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n",
    "            ohe_features = ohe.get_feature_names_out(categorical_cols)\n",
    "            all_features = list(ohe_features) + numerical_cols\n",
    "        else:\n",
    "            all_features = numerical_cols\n",
    "        \n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            # Para modelos como Random Forest\n",
    "            importances = pd.Series(model.feature_importances_, index=all_features)\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            # Para modelos lineares\n",
    "            importances = pd.Series(abs(model.coef_), index=all_features)\n",
    "        else:\n",
    "            print(f\"{name} não possui atributo de importância das features.\")\n",
    "            continue\n",
    "        \n",
    "        # Normalização das importâncias\n",
    "        importances = importances / importances.sum()\n",
    "        \n",
    "        # Acumulação das importâncias\n",
    "        feature_importances = feature_importances.add(importances, fill_value=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao coletar importâncias das features para {name}: {e}\")\n",
    "\n",
    "# Média das importâncias\n",
    "feature_importances = feature_importances / len(pipelines)\n",
    "\n",
    "# Seleção das 10 features mais importantes\n",
    "top_10_features = feature_importances.sort_values(ascending=False).head(10)\n",
    "\n",
    "print(\"\\nTop 10 Features Mais Importantes:\")\n",
    "print(top_10_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exibição das 10 Features Mais Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização das 10 features mais importantes\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=top_10_features.values, y=top_10_features.index, palette='viridis')\n",
    "plt.title('Top 10 Features Mais Importantes')\n",
    "plt.xlabel('Importância Média')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação Final entre os Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificação do modelo com menor Erro Percentual\n",
    "best_model = results_df.loc[results_df['Erro Percentual (%)'].astype(float).idxmin()]\n",
    "\n",
    "print(\"\\nModelo com menor erro percentual (Erro Percentual):\")\n",
    "print(f\"Modelo: {best_model['Modelo']}\")\n",
    "print(f\"RMSE: {best_model['RMSE']}\")\n",
    "print(f\"Erro Percentual: {best_model['Erro Percentual (%)']}\")\n",
    "print(f\"Melhores Hiperparâmetros: {best_model['Melhores Hiperparâmetros']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
